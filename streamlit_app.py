# streamlit_app.py

import os
import streamlit as st
import pandas as pd
import requests
from pathlib import Path

st.set_page_config(
    page_title="CÄƒutare firme dupÄƒ CUI (Drive + local)",
    layout="wide",
)
st.title("ğŸ” CÄƒutare firme dupÄƒ CUI")

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1) Configurare Google Drive pentru fiÈ™ierul mare
DRIVE_ID_LARGE = "1xfyW-Y8JhpGG2lTP6YcdC6kHuk7DBz3A"  # â† pune ID-ul tÄƒu aici
LOCAL_LARGE_PATH = Path("/mnt/data/web_uu_an2024_convertit.csv")
DOWNLOAD_URL = "https://docs.google.com/uc?export=download"

def get_confirm_token(response):
    for key, value in response.cookies.items():
        if key.startswith("download_warning"):
            return value
    return None

def download_file_from_google_drive(file_id: str, destination: Path):
    session = requests.Session()
    res = session.get(DOWNLOAD_URL, params={"id": file_id}, stream=True)
    token = get_confirm_token(res)
    if token:
        res = session.get(
            DOWNLOAD_URL,
            params={"id": file_id, "confirm": token},
            stream=True
        )
    with open(destination, "wb") as f:
        for chunk in res.iter_content(32768):
            if chunk:
                f.write(chunk)

@st.cache_data(show_spinner=True)
def load_large_csv() -> pd.DataFrame:
    if not LOCAL_LARGE_PATH.exists():
        st.info("ğŸ”„ DescarcÄƒ fiÈ™ierul mare de pe Drive (75 MB)â€¦")
        download_file_from_google_drive(DRIVE_ID_LARGE, LOCAL_LARGE_PATH)
    return pd.read_csv(LOCAL_LARGE_PATH, dtype=str, low_memory=False)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 2) ÃncarcÄƒ CSV-ul mare + CSV-ul mic din folderul `data/`
df_large = load_large_csv()
st.info(f"âœ”ï¸  FiÈ™ier mare Ã®ncÄƒrcat: {df_large.shape[0]} rÃ¢nduri Ã— {df_large.shape[1]} coloane")

DATA_DIR = Path(__file__).parent / "data"
SMALL_CSV_NAME = "web_bl_bs_sl_an2024_convertit.csv"
small_path = DATA_DIR / SMALL_CSV_NAME

if small_path.exists():
    df_small = pd.read_csv(small_path, dtype=str, low_memory=False)
    st.info(f"âœ”ï¸  FiÈ™ier mic Ã®ncÄƒrcat:  {df_small.shape[0]} rÃ¢nduri Ã— {df_small.shape[1]} coloane")
    df = pd.concat([df_large, df_small], ignore_index=True)
else:
    st.warning(f"FiÈ™ierul mic `{SMALL_CSV_NAME}` nu a fost gÄƒsit Ã®n `{DATA_DIR}`; folosesc doar CSV-ul mare.")
    df = df_large

st.success(f"âœ… Total date: {df.shape[0]} rÃ¢nduri Ã— {df.shape[1]} coloane")

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 3) VerificÄƒ existenÈ›a coloanei CUI
if "CUI" not in df.columns:
    st.error("Coloana 'CUI' nu existÄƒ Ã®n date. AsigurÄƒ-te cÄƒ ai coloana exact 'CUI'.")
    st.stop()

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 4) CÄƒutare dupÄƒ CUI
cui_input = st.text_input("ğŸ” Introdu CUI (sau fragment de CUI)", "")
exact = st.checkbox("CÄƒutare exactÄƒ", value=False)

if cui_input:
    s = cui_input.strip()
    if exact:
        mask = df["CUI"].str.strip().eq(s, na=False)
    else:
        mask = df["CUI"].str.contains(s, na=False)
    results = df[mask]
    if not results.empty:
        st.write(f"**{len(results)}** firme gÄƒsite:")
        st.dataframe(results.reset_index(drop=True))
    else:
        st.warning("Nicio firmÄƒ gÄƒsitÄƒ cu acest CUI.")
else:
    st.info("Introdu un CUI Ã®n caseta de mai sus pentru a cÄƒuta.")
